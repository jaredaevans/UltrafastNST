{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from ImageTransformer import ImageTransformer\n",
    "from trainer import Trainer\n",
    "from datasets import InputDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Paths & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main_path = \"PATH/TO/IMAGE/DIR/\"\n",
    "style_dir = \"PATH/TO/STYLE/IMAGE/DIR/\"\n",
    "test_image_path = \"/content/Bacchus.jpg\"\n",
    "IDtail = \"_0.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reload_model():\n",
    "    return ImageTransformer(leak=0,\n",
    "                            norm_type='batch',\n",
    "                            DWS=True,\n",
    "                            DWSFL=False,\n",
    "                            outerK=3,\n",
    "                            resgroups=4,\n",
    "                            filters=[8, 12, 16],\n",
    "                            shuffle=True,\n",
    "                            blocks=[2, 2, 2, 1, 1, 1],\n",
    "                            endgroups=(1, 1),\n",
    "                            upkern=3,\n",
    "                            bias_ll=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load device for gpu or cpu running (GPU recommended)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load a dataset of jpgs, pngs, etc  (NOTE: Not linked)\n",
    "contentims_raw = os.listdir(main_path)\n",
    "contentims = []\n",
    "for path in contentims_raw:\n",
    "    if path[:1] != \".\":\n",
    "        contentims.append(path)\n",
    "cutoff = 0.85 * len(contentims)\n",
    "cutoff = (cutoff // 16) * 16\n",
    "contenttrain = contentims[:cutoff]\n",
    "contentval = contentims[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T03:06:40.808802Z",
     "start_time": "2020-10-01T03:06:40.786103Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load various functions and transformations for image I/O\n",
    "transformPILtoTensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transformTensortoPIL = transforms.Compose([\n",
    "    transforms.Normalize((-1., -1., -1.), (2., 2., 2.)),\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "\n",
    "def load_img_x(path_to_img, max_dim=512):\n",
    "    # for loading style image\n",
    "    img = Image.open(path_to_img)\n",
    "    shape = img.size\n",
    "    short_dim = min(shape)\n",
    "    scale = max_dim / short_dim\n",
    "    img = img.resize((int(shape[0] * scale), int(shape[1] * scale)))\n",
    "    imgs = transformPILtoTensor(img).unsqueeze(0).to(device, torch.float)\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def load_img_reshape(path_to_img, max_dim=512):\n",
    "    img = Image.open(path_to_img)\n",
    "    shape = img.size\n",
    "    short_dim = min(shape)\n",
    "    scale = max_dim / short_dim\n",
    "    img = img.resize((int(shape[0] * scale), int(shape[1] * scale)))\n",
    "    new_shape = img.size\n",
    "    os_h = int((new_shape[0] - max_dim) / 2)\n",
    "    os_w = int((new_shape[1] - max_dim) / 2)\n",
    "    img = img.crop((os_h, os_w, os_h + max_dim, os_w + max_dim))\n",
    "    imgs = transformPILtoTensor(img).unsqueeze(0).to(torch.float)\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def load_prepped_img(path_to_img):\n",
    "    img = Image.open(path_to_img)\n",
    "    imgs = transformPILtoTensor(img).unsqueeze(0).to(torch.float)\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def load_data(content, resize=False):\n",
    "    if resize:\n",
    "        load_func = load_img_reshape\n",
    "    else:\n",
    "        load_func = load_prepped_img\n",
    "    x = load_func(mainpath + content[0])\n",
    "    for path in content[1:]:\n",
    "        x = torch.cat((x, load_func(mainpath + path)), 0)\n",
    "    print(x.shape)\n",
    "    return x\n",
    "\n",
    "\n",
    "def prepandclip(img):\n",
    "    return img.squeeze().data.clamp_(-1, 1).cpu().detach()\n",
    "\n",
    "\n",
    "def show_test_image_quality(model, image, device=device):\n",
    "    model_input = image.clone()\n",
    "    image = (image.squeeze(0).permute(1, 2, 0) + 1.) / 2\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('input')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_input = model_input.to(device)\n",
    "        model_output = model(model_input)\n",
    "    output = prepandclip(model_output)\n",
    "    output = (output.permute(1, 2, 0) + 1.) / 2\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(output)\n",
    "    plt.axis('off')\n",
    "    plt.title('output')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_image = load_img_x(test_image_path, max_dim=300)\n",
    "\n",
    "# create a torch tensor of images that are that have been  cropped with correct aspect\n",
    "xtrain = load_data(contenttrain)\n",
    "xval = load_data(contentval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_trainer(image_transformer,\n",
    "                xtrain,\n",
    "                xval,\n",
    "                content_layers,\n",
    "                style_layers,\n",
    "                style_path,\n",
    "                outfile,\n",
    "                content_style_layers=None,\n",
    "                epochs=50,\n",
    "                patience=5,\n",
    "                style_weight=(0, 10),\n",
    "                content_weight=1,\n",
    "                cs_weight=50,\n",
    "                tv_weight=1000,\n",
    "                stable_weight=2000,\n",
    "                pretrained_filename=None,\n",
    "                test_image=None):\n",
    "    # load image trainsformer and trained AE\n",
    "    if pretrained_filename is not None:\n",
    "        image_transformer.load_state_dict(torch.load(pretrained_filename))\n",
    "    style_image = load_img_x(style_path, max_dim=512)\n",
    "    trainer = Trainer(image_transformer, content_layers, style_layers,\n",
    "                      style_image, content_style_layers)\n",
    "    # prep train data\n",
    "    datasettrain = InputDataset(xtrain)\n",
    "    # prep val data\n",
    "    datasetval = InputDataset(xval)\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        print(torch.cuda.memory_summary(abbreviated=True))\n",
    "    # train\n",
    "    trainer.train(datasettrain,\n",
    "                  val=datasetval,\n",
    "                  epochs=epochs,\n",
    "                  epoch_show=1,\n",
    "                  style_weight=style_weight,\n",
    "                  content_weight=content_weight,\n",
    "                  stable_weight=stable_weight,\n",
    "                  tv_weight=tv_weight,\n",
    "                  cs_weight=cs_weight,\n",
    "                  es_patience=patience,\n",
    "                  best_path=\"best.pth\",\n",
    "                  test_image=test_image)\n",
    "    # revert to best and save\n",
    "    image_transformer.load_state_dict(torch.load(\"best.pth\"))\n",
    "    torch.save(image_transformer.state_dict(), outfile)\n",
    "    del trainer\n",
    "    del datasettrain\n",
    "    del datasetval\n",
    "    del image_transformer\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layers = ['relu_7']\n",
    "style_layers = ['relu_2', 'relu_4', 'relu_7', 'relu_11', 'relu_15']\n",
    "content_style_layers = None\n",
    "style_path = style_dir + \"Munch-The_Scream.jpg\"\n",
    "outfile = \"scream_bench\" + IDtail\n",
    "image_transformer = reload_model()\n",
    "run_trainer(image_transformer, xtrain, xval,\n",
    "            content_layers, style_layers, \n",
    "            style_path,outfile,\n",
    "            content_style_layers=content_style_layers,\n",
    "            pretrained_filename=None,\n",
    "            epochs=50, patience=5,\n",
    "            test_image=test_image,\n",
    "            style_weight=(20, 0),\n",
    "            cs_weight=0,\n",
    "            content_weight=1,\n",
    "            stable_weight=2000,\n",
    "            tv_weight=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
